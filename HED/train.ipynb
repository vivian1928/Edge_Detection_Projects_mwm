{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"train.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyPU7AJOtLI9482jTLX2dKn0"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"G4POisoPCybR","executionInfo":{"status":"ok","timestamp":1636036103932,"user_tz":-480,"elapsed":4661,"user":{"displayName":"孟维民","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01682933707738661337"}},"outputId":"e3aa3dc3-989f-4f38-bb4d-e12e1fc94555"},"source":["from google.colab import drive  # 接入Colab\n","drive.mount('/content/drive')"],"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","metadata":{"id":"jad3aeaoDAlg","colab":{"base_uri":"https://localhost:8080/","height":186},"executionInfo":{"status":"error","timestamp":1636036108482,"user_tz":-480,"elapsed":20,"user":{"displayName":"孟维民","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01682933707738661337"}},"outputId":"d7dae18c-9657-49dd-921f-f0b9267ecbd5"},"source":["import os   #设置目录位置\n","os.chdir('drive/My Drive')"],"execution_count":11,"outputs":[{"output_type":"error","ename":"FileNotFoundError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-11-07cb60d6b6bd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m   \u001b[0;31m#设置目录位置\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'drive/My Drive'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'drive/My Drive'"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ocdT2QsZWid6","executionInfo":{"status":"ok","timestamp":1636036130395,"user_tz":-480,"elapsed":397,"user":{"displayName":"孟维民","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01682933707738661337"}},"outputId":"470e1cc5-c110-4b69-8bf9-3be904f43c15"},"source":["!pwd"],"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/My Drive/HED\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rVQwSucZWfyr","executionInfo":{"status":"ok","timestamp":1636036170415,"user_tz":-480,"elapsed":380,"user":{"displayName":"孟维民","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01682933707738661337"}},"outputId":"4a604ee5-f4d5-42ea-f969-fdb974c2c291"},"source":["%cd '..'"],"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/My Drive\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fEC5NIdIWtr9","executionInfo":{"status":"ok","timestamp":1636036203083,"user_tz":-480,"elapsed":7199,"user":{"displayName":"孟维民","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01682933707738661337"}},"outputId":"cf1f7dd9-90ad-4530-d5e7-f207fcf967e7"},"source":["!unzip 'Edge-Detection-Using-ML-main.zip'"],"execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["Archive:  Edge-Detection-Using-ML-main.zip\n","c71ec0ca2f3875209d168cd09aa2164ec0202fff\n","   creating: Edge-Detection-Using-ML-main/\n","   creating: Edge-Detection-Using-ML-main/.ipynb_checkpoints/\n","  inflating: Edge-Detection-Using-ML-main/.ipynb_checkpoints/DexiNed-checkpoint.ipynb  \n","  inflating: Edge-Detection-Using-ML-main/.ipynb_checkpoints/InitialImplementation-checkpoint.ipynb  \n","   creating: Edge-Detection-Using-ML-main/BIPED/\n","   creating: Edge-Detection-Using-ML-main/BIPED/edges/\n","   creating: Edge-Detection-Using-ML-main/BIPED/edges/edge_maps/\n","   creating: Edge-Detection-Using-ML-main/BIPED/edges/edge_maps/test/\n","   creating: Edge-Detection-Using-ML-main/BIPED/edges/edge_maps/test/rgbr/\n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/edge_maps/test/rgbr/RGB_008.png  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/edge_maps/test/rgbr/RGB_010.png  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/edge_maps/test/rgbr/RGB_017.png  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/edge_maps/test/rgbr/RGB_025.png  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/edge_maps/test/rgbr/RGB_029.png  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/edge_maps/test/rgbr/RGB_033.png  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/edge_maps/test/rgbr/RGB_035.png  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/edge_maps/test/rgbr/RGB_039.png  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/edge_maps/test/rgbr/RGB_042.png  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/edge_maps/test/rgbr/RGB_052.png  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/edge_maps/test/rgbr/RGB_056.png  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/edge_maps/test/rgbr/RGB_057.png  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/edge_maps/test/rgbr/RGB_059.png  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/edge_maps/test/rgbr/RGB_066.png  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/edge_maps/test/rgbr/RGB_067.png  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/edge_maps/test/rgbr/RGB_070.png  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/edge_maps/test/rgbr/RGB_071.png  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/edge_maps/test/rgbr/RGB_075.png  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/edge_maps/test/rgbr/RGB_081.png  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/edge_maps/test/rgbr/RGB_083.png  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/edge_maps/test/rgbr/RGB_090.png  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/edge_maps/test/rgbr/RGB_092.png  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/edge_maps/test/rgbr/RGB_094.png  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/edge_maps/test/rgbr/RGB_098.png  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/edge_maps/test/rgbr/RGB_102.png  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/edge_maps/test/rgbr/RGB_107.png  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/edge_maps/test/rgbr/RGB_111.png  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/edge_maps/test/rgbr/RGB_120.png  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/edge_maps/test/rgbr/RGB_124.png  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/edge_maps/test/rgbr/RGB_132.png  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/edge_maps/test/rgbr/RGB_138.png  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/edge_maps/test/rgbr/RGB_139.png  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/edge_maps/test/rgbr/RGB_141.png  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/edge_maps/test/rgbr/RGB_145.png  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/edge_maps/test/rgbr/RGB_160.png  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/edge_maps/test/rgbr/RGB_170.png  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/edge_maps/test/rgbr/RGB_181.png  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/edge_maps/test/rgbr/RGB_182.png  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/edge_maps/test/rgbr/RGB_190.png  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/edge_maps/test/rgbr/RGB_192.png  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/edge_maps/test/rgbr/RGB_206.png  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/edge_maps/test/rgbr/RGB_212.png  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/edge_maps/test/rgbr/RGB_214.png  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/edge_maps/test/rgbr/RGB_226.png  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/edge_maps/test/rgbr/RGB_228.png  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/edge_maps/test/rgbr/RGB_234.png  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/edge_maps/test/rgbr/RGB_237.png  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/edge_maps/test/rgbr/RGB_247.png  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/edge_maps/test/rgbr/RGB_248.png  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/edge_maps/test/rgbr/RGB_254.png  \n","   creating: Edge-Detection-Using-ML-main/BIPED/edges/edge_maps/train/\n","   creating: Edge-Detection-Using-ML-main/BIPED/edges/edge_maps/train/rgbr/\n","   creating: Edge-Detection-Using-ML-main/BIPED/edges/edge_maps/train/rgbr/real/\n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/edge_maps/train/rgbr/real/RGB_001.png  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/edge_maps/train/rgbr/real/RGB_002.png  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/edge_maps/train/rgbr/real/RGB_003.png  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/edge_maps/train/rgbr/real/RGB_004.png  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/edge_maps/train/rgbr/real/RGB_005.png  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/edge_maps/train/rgbr/real/RGB_006.png  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/edge_maps/train/rgbr/real/RGB_007.png  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/edge_maps/train/rgbr/real/RGB_009.png  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/edge_maps/train/rgbr/real/RGB_011.png  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/edge_maps/train/rgbr/real/RGB_012.png  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/edge_maps/train/rgbr/real/RGB_013.png  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/edge_maps/train/rgbr/real/RGB_014.png  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/edge_maps/train/rgbr/real/RGB_015.png  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/edge_maps/train/rgbr/real/RGB_016.png  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/edge_maps/train/rgbr/real/RGB_018.png  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/edge_maps/train/rgbr/real/RGB_019.png  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/edge_maps/train/rgbr/real/RGB_020.png  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/edge_maps/train/rgbr/real/RGB_021.png  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/edge_maps/train/rgbr/real/RGB_022.png  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/edge_maps/train/rgbr/real/RGB_023.png  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/edge_maps/train/rgbr/real/RGB_024.png  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/edge_maps/train/rgbr/real/RGB_026.png  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/edge_maps/train/rgbr/real/RGB_027.png  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/edge_maps/train/rgbr/real/RGB_028.png  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/edge_maps/train/rgbr/real/RGB_030.png  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/edge_maps/train/rgbr/real/RGB_031.png  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/edge_maps/train/rgbr/real/RGB_032.png  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/edge_maps/train/rgbr/real/RGB_034.png  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/edge_maps/train/rgbr/real/RGB_036.png  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/edge_maps/train/rgbr/real/RGB_037.png  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/edge_maps/train/rgbr/real/RGB_038.png  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/edge_maps/train/rgbr/real/RGB_040.png  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/edge_maps/train/rgbr/real/RGB_041.png  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/edge_maps/train/rgbr/real/RGB_043.png  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/edge_maps/train/rgbr/real/RGB_044.png  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/edge_maps/train/rgbr/real/RGB_045.png  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/edge_maps/train/rgbr/real/RGB_046.png  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/edge_maps/train/rgbr/real/RGB_047.png  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/edge_maps/train/rgbr/real/RGB_048.png  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/edge_maps/train/rgbr/real/RGB_049.png  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/edge_maps/train/rgbr/real/RGB_050.png  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/edge_maps/train/rgbr/real/RGB_051.png  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/edge_maps/train/rgbr/real/RGB_053.png  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/edge_maps/train/rgbr/real/RGB_054.png  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/edge_maps/train/rgbr/real/RGB_055.png  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/edge_maps/train/rgbr/real/RGB_058.png  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/edge_maps/train/rgbr/real/RGB_060.png  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/edge_maps/train/rgbr/real/RGB_061.png  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/edge_maps/train/rgbr/real/RGB_062.png  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/edge_maps/train/rgbr/real/RGB_063.png  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/edge_maps/train/rgbr/real/RGB_064.png  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/edge_maps/train/rgbr/real/RGB_065.png  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/edge_maps/train/rgbr/real/RGB_068.png  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/edge_maps/train/rgbr/real/RGB_069.png  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/edge_maps/train/rgbr/real/RGB_072.png  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/edge_maps/train/rgbr/real/RGB_073.png  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/edge_maps/train/rgbr/real/RGB_074.png  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/edge_maps/train/rgbr/real/RGB_076.png  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/edge_maps/train/rgbr/real/RGB_077.png  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/edge_maps/train/rgbr/real/RGB_078.png  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/edge_maps/train/rgbr/real/RGB_079.png  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/edge_maps/train/rgbr/real/RGB_080.png  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/edge_maps/train/rgbr/real/RGB_082.png  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/edge_maps/train/rgbr/real/RGB_084.png  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/edge_maps/train/rgbr/real/RGB_085.png  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/edge_maps/train/rgbr/real/RGB_086.png  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/edge_maps/train/rgbr/real/RGB_087.png  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/edge_maps/train/rgbr/real/RGB_088.png  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/edge_maps/train/rgbr/real/RGB_089.png  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/edge_maps/train/rgbr/real/RGB_091.png  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/edge_maps/train/rgbr/real/RGB_093.png  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/edge_maps/train/rgbr/real/RGB_095.png  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/edge_maps/train/rgbr/real/RGB_096.png  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/edge_maps/train/rgbr/real/RGB_097.png  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/edge_maps/train/rgbr/real/RGB_099.png  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/edge_maps/train/rgbr/real/RGB_100.png  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/edge_maps/train/rgbr/real/RGB_101.png  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/edge_maps/train/rgbr/real/RGB_103.png  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/edge_maps/train/rgbr/real/RGB_104.png  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/edge_maps/train/rgbr/real/RGB_105.png  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/edge_maps/train/rgbr/real/RGB_106.png  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/edge_maps/train/rgbr/real/RGB_108.png  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/edge_maps/train/rgbr/real/RGB_109.png  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/edge_maps/train/rgbr/real/RGB_110.png  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/edge_maps/train/rgbr/real/RGB_112.png  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/edge_maps/train/rgbr/real/RGB_113.png  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/edge_maps/train/rgbr/real/RGB_114.png  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/edge_maps/train/rgbr/real/RGB_115.png  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/edge_maps/train/rgbr/real/RGB_116.png  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/edge_maps/train/rgbr/real/RGB_117.png  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/edge_maps/train/rgbr/real/RGB_118.png  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/edge_maps/train/rgbr/real/RGB_119.png  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/edge_maps/train/rgbr/real/RGB_121.png  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/edge_maps/train/rgbr/real/RGB_122.png  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/edge_maps/train/rgbr/real/RGB_123.png  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/edge_maps/train/rgbr/real/RGB_126.png  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/edge_maps/train/rgbr/real/RGB_127.png  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/edge_maps/train/rgbr/real/RGB_128.png  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/edge_maps/train/rgbr/real/RGB_129.png  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/edge_maps/train/rgbr/real/RGB_130.png  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/edge_maps/train/rgbr/real/RGB_131.png  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/edge_maps/train/rgbr/real/RGB_134.png  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/edge_maps/train/rgbr/real/RGB_135.png  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/edge_maps/train/rgbr/real/RGB_136.png  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/edge_maps/train/rgbr/real/RGB_137.png  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/edge_maps/train/rgbr/real/RGB_140.png  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/edge_maps/train/rgbr/real/RGB_142.png  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/edge_maps/train/rgbr/real/RGB_143.png  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/edge_maps/train/rgbr/real/RGB_144.png  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/edge_maps/train/rgbr/real/RGB_146.png  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/edge_maps/train/rgbr/real/RGB_147.png  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/edge_maps/train/rgbr/real/RGB_148.png  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/edge_maps/train/rgbr/real/RGB_149.png  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/edge_maps/train/rgbr/real/RGB_151.png  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/edge_maps/train/rgbr/real/RGB_152.png  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/edge_maps/train/rgbr/real/RGB_153.png  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/edge_maps/train/rgbr/real/RGB_154.png  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/edge_maps/train/rgbr/real/RGB_155.png  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/edge_maps/train/rgbr/real/RGB_156.png  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/edge_maps/train/rgbr/real/RGB_157.png  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/edge_maps/train/rgbr/real/RGB_158.png  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/edge_maps/train/rgbr/real/RGB_159.png  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/edge_maps/train/rgbr/real/RGB_161.png  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/edge_maps/train/rgbr/real/RGB_162.png  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/edge_maps/train/rgbr/real/RGB_163.png  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/edge_maps/train/rgbr/real/RGB_164.png  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/edge_maps/train/rgbr/real/RGB_165.png  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/edge_maps/train/rgbr/real/RGB_166.png  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/edge_maps/train/rgbr/real/RGB_167.png  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/edge_maps/train/rgbr/real/RGB_168.png  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/edge_maps/train/rgbr/real/RGB_169.png  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/edge_maps/train/rgbr/real/RGB_171.png  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/edge_maps/train/rgbr/real/RGB_172.png  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/edge_maps/train/rgbr/real/RGB_173.png  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/edge_maps/train/rgbr/real/RGB_174.png  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/edge_maps/train/rgbr/real/RGB_175.png  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/edge_maps/train/rgbr/real/RGB_176.png  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/edge_maps/train/rgbr/real/RGB_177.png  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/edge_maps/train/rgbr/real/RGB_178.png  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/edge_maps/train/rgbr/real/RGB_179.png  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/edge_maps/train/rgbr/real/RGB_180.png  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/edge_maps/train/rgbr/real/RGB_183.png  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/edge_maps/train/rgbr/real/RGB_184.png  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/edge_maps/train/rgbr/real/RGB_185.png  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/edge_maps/train/rgbr/real/RGB_186.png  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/edge_maps/train/rgbr/real/RGB_187.png  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/edge_maps/train/rgbr/real/RGB_188.png  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/edge_maps/train/rgbr/real/RGB_191.png  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/edge_maps/train/rgbr/real/RGB_193.png  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/edge_maps/train/rgbr/real/RGB_194.png  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/edge_maps/train/rgbr/real/RGB_195.png  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/edge_maps/train/rgbr/real/RGB_196.png  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/edge_maps/train/rgbr/real/RGB_197.png  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/edge_maps/train/rgbr/real/RGB_198.png  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/edge_maps/train/rgbr/real/RGB_199.png  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/edge_maps/train/rgbr/real/RGB_200.png  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/edge_maps/train/rgbr/real/RGB_201.png  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/edge_maps/train/rgbr/real/RGB_202.png  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/edge_maps/train/rgbr/real/RGB_203.png  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/edge_maps/train/rgbr/real/RGB_204.png  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/edge_maps/train/rgbr/real/RGB_205.png  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/edge_maps/train/rgbr/real/RGB_207.png  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/edge_maps/train/rgbr/real/RGB_208.png  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/edge_maps/train/rgbr/real/RGB_209.png  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/edge_maps/train/rgbr/real/RGB_210.png  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/edge_maps/train/rgbr/real/RGB_211.png  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/edge_maps/train/rgbr/real/RGB_213.png  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/edge_maps/train/rgbr/real/RGB_216.png  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/edge_maps/train/rgbr/real/RGB_217.png  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/edge_maps/train/rgbr/real/RGB_218.png  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/edge_maps/train/rgbr/real/RGB_219.png  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/edge_maps/train/rgbr/real/RGB_220.png  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/edge_maps/train/rgbr/real/RGB_221.png  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/edge_maps/train/rgbr/real/RGB_222.png  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/edge_maps/train/rgbr/real/RGB_223.png  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/edge_maps/train/rgbr/real/RGB_224.png  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/edge_maps/train/rgbr/real/RGB_225.png  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/edge_maps/train/rgbr/real/RGB_227.png  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/edge_maps/train/rgbr/real/RGB_229.png  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/edge_maps/train/rgbr/real/RGB_230.png  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/edge_maps/train/rgbr/real/RGB_231.png  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/edge_maps/train/rgbr/real/RGB_233.png  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/edge_maps/train/rgbr/real/RGB_235.png  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/edge_maps/train/rgbr/real/RGB_236.png  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/edge_maps/train/rgbr/real/RGB_238.png  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/edge_maps/train/rgbr/real/RGB_239.png  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/edge_maps/train/rgbr/real/RGB_240.png  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/edge_maps/train/rgbr/real/RGB_241.png  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/edge_maps/train/rgbr/real/RGB_242.png  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/edge_maps/train/rgbr/real/RGB_244.png  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/edge_maps/train/rgbr/real/RGB_245.png  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/edge_maps/train/rgbr/real/RGB_246.png  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/edge_maps/train/rgbr/real/RGB_249.png  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/edge_maps/train/rgbr/real/RGB_250.png  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/edge_maps/train/rgbr/real/RGB_251.png  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/edge_maps/train/rgbr/real/RGB_252.png  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/edge_maps/train/rgbr/real/RGB_255.png  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/edge_maps/train/rgbr/real/RGB_256.png  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/edge_maps/train/rgbr/real/RGB_257.png  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/edge_maps/train/rgbr/real/RGB_258.png  \n","   creating: Edge-Detection-Using-ML-main/BIPED/edges/imgs/\n","   creating: Edge-Detection-Using-ML-main/BIPED/edges/imgs/test/\n","   creating: Edge-Detection-Using-ML-main/BIPED/edges/imgs/test/rgbr/\n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/imgs/test/rgbr/RGB_008.jpg  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/imgs/test/rgbr/RGB_010.jpg  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/imgs/test/rgbr/RGB_017.jpg  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/imgs/test/rgbr/RGB_025.jpg  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/imgs/test/rgbr/RGB_029.jpg  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/imgs/test/rgbr/RGB_033.jpg  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/imgs/test/rgbr/RGB_035.jpg  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/imgs/test/rgbr/RGB_039.jpg  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/imgs/test/rgbr/RGB_042.jpg  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/imgs/test/rgbr/RGB_052.jpg  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/imgs/test/rgbr/RGB_056.jpg  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/imgs/test/rgbr/RGB_057.jpg  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/imgs/test/rgbr/RGB_059.jpg  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/imgs/test/rgbr/RGB_066.jpg  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/imgs/test/rgbr/RGB_067.jpg  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/imgs/test/rgbr/RGB_070.jpg  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/imgs/test/rgbr/RGB_071.jpg  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/imgs/test/rgbr/RGB_075.jpg  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/imgs/test/rgbr/RGB_081.jpg  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/imgs/test/rgbr/RGB_083.jpg  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/imgs/test/rgbr/RGB_090.jpg  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/imgs/test/rgbr/RGB_092.jpg  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/imgs/test/rgbr/RGB_094.jpg  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/imgs/test/rgbr/RGB_098.jpg  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/imgs/test/rgbr/RGB_102.jpg  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/imgs/test/rgbr/RGB_107.jpg  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/imgs/test/rgbr/RGB_111.jpg  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/imgs/test/rgbr/RGB_120.jpg  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/imgs/test/rgbr/RGB_124.jpg  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/imgs/test/rgbr/RGB_132.jpg  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/imgs/test/rgbr/RGB_138.jpg  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/imgs/test/rgbr/RGB_139.jpg  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/imgs/test/rgbr/RGB_141.jpg  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/imgs/test/rgbr/RGB_145.jpg  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/imgs/test/rgbr/RGB_160.jpg  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/imgs/test/rgbr/RGB_170.jpg  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/imgs/test/rgbr/RGB_181.jpg  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/imgs/test/rgbr/RGB_182.jpg  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/imgs/test/rgbr/RGB_190.jpg  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/imgs/test/rgbr/RGB_192.jpg  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/imgs/test/rgbr/RGB_206.jpg  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/imgs/test/rgbr/RGB_212.jpg  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/imgs/test/rgbr/RGB_214.jpg  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/imgs/test/rgbr/RGB_226.jpg  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/imgs/test/rgbr/RGB_228.jpg  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/imgs/test/rgbr/RGB_234.jpg  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/imgs/test/rgbr/RGB_237.jpg  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/imgs/test/rgbr/RGB_247.jpg  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/imgs/test/rgbr/RGB_248.jpg  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/imgs/test/rgbr/RGB_254.jpg  \n","   creating: Edge-Detection-Using-ML-main/BIPED/edges/imgs/train/\n","   creating: Edge-Detection-Using-ML-main/BIPED/edges/imgs/train/rgbr/\n","   creating: Edge-Detection-Using-ML-main/BIPED/edges/imgs/train/rgbr/real/\n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/imgs/train/rgbr/real/RGB_001.jpg  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/imgs/train/rgbr/real/RGB_002.jpg  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/imgs/train/rgbr/real/RGB_003.jpg  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/imgs/train/rgbr/real/RGB_004.jpg  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/imgs/train/rgbr/real/RGB_005.jpg  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/imgs/train/rgbr/real/RGB_006.jpg  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/imgs/train/rgbr/real/RGB_007.jpg  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/imgs/train/rgbr/real/RGB_009.jpg  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/imgs/train/rgbr/real/RGB_011.jpg  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/imgs/train/rgbr/real/RGB_012.jpg  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/imgs/train/rgbr/real/RGB_013.jpg  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/imgs/train/rgbr/real/RGB_014.jpg  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/imgs/train/rgbr/real/RGB_015.jpg  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/imgs/train/rgbr/real/RGB_016.jpg  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/imgs/train/rgbr/real/RGB_018.jpg  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/imgs/train/rgbr/real/RGB_019.jpg  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/imgs/train/rgbr/real/RGB_020.jpg  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/imgs/train/rgbr/real/RGB_021.jpg  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/imgs/train/rgbr/real/RGB_022.jpg  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/imgs/train/rgbr/real/RGB_023.jpg  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/imgs/train/rgbr/real/RGB_024.jpg  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/imgs/train/rgbr/real/RGB_026.jpg  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/imgs/train/rgbr/real/RGB_027.jpg  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/imgs/train/rgbr/real/RGB_028.jpg  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/imgs/train/rgbr/real/RGB_030.jpg  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/imgs/train/rgbr/real/RGB_031.jpg  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/imgs/train/rgbr/real/RGB_032.jpg  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/imgs/train/rgbr/real/RGB_034.jpg  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/imgs/train/rgbr/real/RGB_036.jpg  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/imgs/train/rgbr/real/RGB_037.jpg  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/imgs/train/rgbr/real/RGB_038.jpg  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/imgs/train/rgbr/real/RGB_040.jpg  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/imgs/train/rgbr/real/RGB_041.jpg  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/imgs/train/rgbr/real/RGB_043.jpg  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/imgs/train/rgbr/real/RGB_044.jpg  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/imgs/train/rgbr/real/RGB_045.jpg  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/imgs/train/rgbr/real/RGB_046.jpg  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/imgs/train/rgbr/real/RGB_047.jpg  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/imgs/train/rgbr/real/RGB_048.jpg  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/imgs/train/rgbr/real/RGB_049.jpg  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/imgs/train/rgbr/real/RGB_050.jpg  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/imgs/train/rgbr/real/RGB_051.jpg  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/imgs/train/rgbr/real/RGB_053.jpg  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/imgs/train/rgbr/real/RGB_054.jpg  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/imgs/train/rgbr/real/RGB_055.jpg  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/imgs/train/rgbr/real/RGB_058.jpg  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/imgs/train/rgbr/real/RGB_060.jpg  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/imgs/train/rgbr/real/RGB_061.jpg  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/imgs/train/rgbr/real/RGB_062.jpg  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/imgs/train/rgbr/real/RGB_063.jpg  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/imgs/train/rgbr/real/RGB_064.jpg  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/imgs/train/rgbr/real/RGB_065.jpg  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/imgs/train/rgbr/real/RGB_068.jpg  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/imgs/train/rgbr/real/RGB_069.jpg  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/imgs/train/rgbr/real/RGB_072.jpg  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/imgs/train/rgbr/real/RGB_073.jpg  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/imgs/train/rgbr/real/RGB_074.jpg  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/imgs/train/rgbr/real/RGB_076.jpg  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/imgs/train/rgbr/real/RGB_077.jpg  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/imgs/train/rgbr/real/RGB_078.jpg  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/imgs/train/rgbr/real/RGB_079.jpg  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/imgs/train/rgbr/real/RGB_080.jpg  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/imgs/train/rgbr/real/RGB_082.jpg  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/imgs/train/rgbr/real/RGB_084.jpg  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/imgs/train/rgbr/real/RGB_085.jpg  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/imgs/train/rgbr/real/RGB_086.jpg  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/imgs/train/rgbr/real/RGB_087.jpg  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/imgs/train/rgbr/real/RGB_088.jpg  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/imgs/train/rgbr/real/RGB_089.jpg  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/imgs/train/rgbr/real/RGB_091.jpg  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/imgs/train/rgbr/real/RGB_093.jpg  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/imgs/train/rgbr/real/RGB_095.jpg  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/imgs/train/rgbr/real/RGB_096.jpg  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/imgs/train/rgbr/real/RGB_097.jpg  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/imgs/train/rgbr/real/RGB_099.jpg  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/imgs/train/rgbr/real/RGB_100.jpg  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/imgs/train/rgbr/real/RGB_101.jpg  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/imgs/train/rgbr/real/RGB_103.jpg  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/imgs/train/rgbr/real/RGB_104.jpg  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/imgs/train/rgbr/real/RGB_105.jpg  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/imgs/train/rgbr/real/RGB_106.jpg  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/imgs/train/rgbr/real/RGB_108.jpg  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/imgs/train/rgbr/real/RGB_109.jpg  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/imgs/train/rgbr/real/RGB_110.jpg  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/imgs/train/rgbr/real/RGB_112.jpg  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/imgs/train/rgbr/real/RGB_113.jpg  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/imgs/train/rgbr/real/RGB_114.jpg  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/imgs/train/rgbr/real/RGB_115.jpg  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/imgs/train/rgbr/real/RGB_116.jpg  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/imgs/train/rgbr/real/RGB_117.jpg  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/imgs/train/rgbr/real/RGB_118.jpg  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/imgs/train/rgbr/real/RGB_119.jpg  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/imgs/train/rgbr/real/RGB_121.jpg  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/imgs/train/rgbr/real/RGB_122.jpg  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/imgs/train/rgbr/real/RGB_123.jpg  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/imgs/train/rgbr/real/RGB_126.jpg  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/imgs/train/rgbr/real/RGB_127.jpg  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/imgs/train/rgbr/real/RGB_128.jpg  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/imgs/train/rgbr/real/RGB_129.jpg  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/imgs/train/rgbr/real/RGB_130.jpg  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/imgs/train/rgbr/real/RGB_131.jpg  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/imgs/train/rgbr/real/RGB_134.jpg  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/imgs/train/rgbr/real/RGB_135.jpg  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/imgs/train/rgbr/real/RGB_136.jpg  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/imgs/train/rgbr/real/RGB_137.jpg  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/imgs/train/rgbr/real/RGB_140.jpg  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/imgs/train/rgbr/real/RGB_142.jpg  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/imgs/train/rgbr/real/RGB_143.jpg  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/imgs/train/rgbr/real/RGB_144.jpg  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/imgs/train/rgbr/real/RGB_146.jpg  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/imgs/train/rgbr/real/RGB_147.jpg  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/imgs/train/rgbr/real/RGB_148.jpg  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/imgs/train/rgbr/real/RGB_149.jpg  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/imgs/train/rgbr/real/RGB_151.jpg  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/imgs/train/rgbr/real/RGB_152.jpg  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/imgs/train/rgbr/real/RGB_153.jpg  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/imgs/train/rgbr/real/RGB_154.jpg  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/imgs/train/rgbr/real/RGB_155.jpg  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/imgs/train/rgbr/real/RGB_156.jpg  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/imgs/train/rgbr/real/RGB_157.jpg  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/imgs/train/rgbr/real/RGB_158.jpg  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/imgs/train/rgbr/real/RGB_159.jpg  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/imgs/train/rgbr/real/RGB_161.jpg  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/imgs/train/rgbr/real/RGB_162.jpg  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/imgs/train/rgbr/real/RGB_163.jpg  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/imgs/train/rgbr/real/RGB_164.jpg  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/imgs/train/rgbr/real/RGB_165.jpg  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/imgs/train/rgbr/real/RGB_166.jpg  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/imgs/train/rgbr/real/RGB_167.jpg  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/imgs/train/rgbr/real/RGB_168.jpg  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/imgs/train/rgbr/real/RGB_169.jpg  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/imgs/train/rgbr/real/RGB_171.jpg  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/imgs/train/rgbr/real/RGB_172.jpg  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/imgs/train/rgbr/real/RGB_173.jpg  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/imgs/train/rgbr/real/RGB_174.jpg  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/imgs/train/rgbr/real/RGB_175.jpg  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/imgs/train/rgbr/real/RGB_176.jpg  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/imgs/train/rgbr/real/RGB_177.jpg  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/imgs/train/rgbr/real/RGB_178.jpg  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/imgs/train/rgbr/real/RGB_179.jpg  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/imgs/train/rgbr/real/RGB_180.jpg  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/imgs/train/rgbr/real/RGB_183.jpg  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/imgs/train/rgbr/real/RGB_184.jpg  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/imgs/train/rgbr/real/RGB_185.jpg  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/imgs/train/rgbr/real/RGB_186.jpg  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/imgs/train/rgbr/real/RGB_187.jpg  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/imgs/train/rgbr/real/RGB_188.jpg  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/imgs/train/rgbr/real/RGB_191.jpg  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/imgs/train/rgbr/real/RGB_193.jpg  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/imgs/train/rgbr/real/RGB_194.jpg  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/imgs/train/rgbr/real/RGB_195.jpg  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/imgs/train/rgbr/real/RGB_196.jpg  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/imgs/train/rgbr/real/RGB_197.jpg  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/imgs/train/rgbr/real/RGB_198.jpg  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/imgs/train/rgbr/real/RGB_199.jpg  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/imgs/train/rgbr/real/RGB_200.jpg  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/imgs/train/rgbr/real/RGB_201.jpg  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/imgs/train/rgbr/real/RGB_202.jpg  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/imgs/train/rgbr/real/RGB_203.jpg  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/imgs/train/rgbr/real/RGB_204.jpg  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/imgs/train/rgbr/real/RGB_205.jpg  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/imgs/train/rgbr/real/RGB_207.jpg  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/imgs/train/rgbr/real/RGB_208.jpg  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/imgs/train/rgbr/real/RGB_209.jpg  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/imgs/train/rgbr/real/RGB_210.jpg  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/imgs/train/rgbr/real/RGB_211.jpg  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/imgs/train/rgbr/real/RGB_213.jpg  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/imgs/train/rgbr/real/RGB_216.jpg  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/imgs/train/rgbr/real/RGB_217.jpg  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/imgs/train/rgbr/real/RGB_218.jpg  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/imgs/train/rgbr/real/RGB_219.jpg  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/imgs/train/rgbr/real/RGB_220.jpg  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/imgs/train/rgbr/real/RGB_221.jpg  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/imgs/train/rgbr/real/RGB_222.jpg  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/imgs/train/rgbr/real/RGB_223.jpg  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/imgs/train/rgbr/real/RGB_224.jpg  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/imgs/train/rgbr/real/RGB_225.jpg  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/imgs/train/rgbr/real/RGB_227.jpg  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/imgs/train/rgbr/real/RGB_229.jpg  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/imgs/train/rgbr/real/RGB_230.jpg  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/imgs/train/rgbr/real/RGB_231.jpg  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/imgs/train/rgbr/real/RGB_233.jpg  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/imgs/train/rgbr/real/RGB_235.jpg  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/imgs/train/rgbr/real/RGB_236.jpg  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/imgs/train/rgbr/real/RGB_238.jpg  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/imgs/train/rgbr/real/RGB_239.jpg  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/imgs/train/rgbr/real/RGB_240.jpg  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/imgs/train/rgbr/real/RGB_241.jpg  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/imgs/train/rgbr/real/RGB_242.jpg  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/imgs/train/rgbr/real/RGB_244.jpg  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/imgs/train/rgbr/real/RGB_245.jpg  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/imgs/train/rgbr/real/RGB_246.jpg  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/imgs/train/rgbr/real/RGB_249.jpg  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/imgs/train/rgbr/real/RGB_250.jpg  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/imgs/train/rgbr/real/RGB_251.jpg  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/imgs/train/rgbr/real/RGB_252.jpg  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/imgs/train/rgbr/real/RGB_255.jpg  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/imgs/train/rgbr/real/RGB_256.jpg  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/imgs/train/rgbr/real/RGB_257.jpg  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/imgs/train/rgbr/real/RGB_258.jpg  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/test_rgb.lst  \n","  inflating: Edge-Detection-Using-ML-main/BIPED/edges/train_rgb.lst  \n","  inflating: Edge-Detection-Using-ML-main/DexiNed.ipynb  \n","  inflating: Edge-Detection-Using-ML-main/InitialImplementation.ipynb  \n","  inflating: Edge-Detection-Using-ML-main/README.md  \n"]}]},{"cell_type":"code","metadata":{"id":"AKCOCCHQD6j4"},"source":["## loss parameters\n","# sides weights\n","sides_weights=1.0 # side0\n","# class balance weights\n","pos_weights=53.4698638405\n","# use deep supervising if is_deep_supervised is true else just using fused side\n","is_deep_supervised=True\n","# use weight decay\n","use_weight_regularizer=True\n","# weight decay ratio\n","weight_decay_ratio=0.0002\n","## train parameters\n","log_dir='logs/'\n","model_weights_path='data/weights/model_weights/'\n","init_weights='data/weights/initial_weights/vgg16.npy'\n","image_path='data/dataset/train_data/'\n","file_name='data/dataset/train.txt'\n","\n","batch_size=3\n","max_epochs=120\n","snapshot_epochs=60\n","\n","height=481\n","width=321\n","channel=3\n","\n","bmean=122.20417892 # blue\n","gmean=119.55591164 # green\n","rmean=123.94569574 # red"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"oGfPRskzDohL"},"source":["# -*- coding: UTF-8 -*-\n","import numpy as np\n","import tensorflow as tf\n","import yaml\n","import cv2\n","import argparse\n","import gc\n","\n","def img_pre_process(img):\n","    '''\n","    图片预处理\n","    :param img: 图片\n","    :param kwargs: 配置信息，如均值\n","    :return: 处理后的图片\n","    '''\n","    def stretch(bands, lower_percent=2, higher_percent=98, bits=8):\n","        if bits not in [8, 16]:\n","            print('error ! dest image must be 8bit or 16bits !')\n","            return\n","        # 创建一个0矩阵shape形同输入的bands\n","        out = np.zeros_like(bands, dtype=np.float32)\n","        n = bands.shape[2]\n","        for i in range(n):\n","            a = 0\n","            b = 1\n","            # numpy.percentile常用于处理离群数据点\n","            c = np.percentile(bands[:, :, i], lower_percent)\n","            d = np.percentile(bands[:, :, i], higher_percent)\n","            if d-c == 0:\n","                out[:, :, i] = 0\n","                continue\n","            t = a + (bands[:, :, i] - c) * (b - a) / (d - c)\n","            # numpy.clip用于将数据元素限制在a,b之间，如t=[1,2,3,4,5],a=2,b=4,np.clip后为[2,2,3,4,4]\n","            out[:, :, i] = np.clip(t, a, b)\n","        if bits == 8:\n","            return out.astype(np.float32)*255\n","        else:\n","            return np.uint16(out.astype(np.float32)*65535)\n","\n","    img = stretch(img)\n","    # 减去配置文件的均值\n","    img -= kwargs['mean']\n","    return img\n","\n","\n","def predict_big_map(img_path, out_shape=(448, 448), inner_shape=(224, 224), out_channel=1, pred_fun=None, **kwargs):\n","    \"\"\"\n","    预测，生成对应的边缘检测图和视频，若图片不一致，会进行切割合成等操作输出固定大小的图片\n","    注：这样进行切割合成的图片对于进行全图边缘检测是可以的，但是对于特定需求边缘检测这样是不合适的。当然如果测试和训练图片大小一致，这个函数同样会输出等大合适的结果\n","    :param img_path: 图片路径\n","    :param out_shape: 输出图片大小\n","    :param inner_shape: 输入图片大小\n","    :param out_channel: 预测图片输出通道，通常为黑白图像，通道数1\n","    :param pred_fun: 前向计算模型，调用sess.run计算hed中间层，返回图片数据\n","    :return: 预测的图片结果\n","    \"\"\"\n","    make_video = True   # 是否生成video文件\n","\n","    image = cv2.imread(img_path, )  #读取图片\n","    # 如果图片只有二维，添加一维生成满足网络要求的占位符比如（?,224,224,1）\n","    if len(image.shape) == 2:\n","        image = np.expand_dims(image, axis=-1)\n","        gc.collect()    # gc为垃圾回收\n","\n","    # 以下大量代码为如果图片大小不满足网络占位符需求，则对图片进行拆分迭代分别计算每个子图片的\n","    pd_up_h, pd_lf_w = np.int64((np.array(out_shape)-np.array(inner_shape)) / 2)\n","    # print(image.shape)\n","    ori_shape = image.shape\n","    pd_bm_h = (out_shape[0]-pd_up_h) - (image.shape[0] % inner_shape[0])\n","    pd_rt_w = (out_shape[1]-pd_lf_w) - (image.shape[1] % inner_shape[1])\n","    it_h = np.int64(np.ceil(1.0*image.shape[0] / inner_shape[0]))\n","    it_w = np.int64(np.ceil(1.0*image.shape[1] / inner_shape[1]))\n","    image_pd = np.pad(image, ((pd_up_h, pd_bm_h), (pd_lf_w, pd_rt_w), (0, 0)), mode='reflect').astype(np.float32)  # the image is default a color one\n","    # print(image_pd.shape)\n","    # print((pd_up_h, pd_bm_h), (pd_lf_w, pd_rt_w))\n","    gc.collect()\n","    tp1 = np.array(inner_shape[0] - ori_shape[0] % inner_shape[0])\n","    tp2 = np.array(inner_shape[1] - ori_shape[1] % inner_shape[1])\n","    if ori_shape[0] % inner_shape[0] == 0:\n","        tp1 = 0\n","    if ori_shape[1] % inner_shape[0] == 0:\n","        tp2 = 0\n","    out_img = np.zeros((ori_shape[0]+tp1, ori_shape[1]+tp2, out_channel), np.float32)\n","\n","    # video config #################################\n","    if make_video:\n","        fps = 24  # 视频帧率\n","        wd = 1360\n","        ht = int(1360*out_img.shape[0]/out_img.shape[1])\n","        # haha = np.zeros((ht, wd, 3), np.uint8)\n","        haha = cv2.resize(np.pad(image, ((0, tp1), (0, tp2), (0, 0)), mode='reflect'), (wd, ht), interpolation=cv2.INTER_LINEAR)\n","        video_writer = cv2.VideoWriter('./data/s2.avi',\n","                                       cv2.VideoWriter_fourcc('M', 'J', 'P', 'G'), fps,\n","                                       (wd, ht))   # isColor=False? (1360,480)为视频大小\n","    image = None  # release memory\n","    # main loop\n","    for ith in range(0, it_h):\n","        h_start = ith * inner_shape[0]\n","        count = 1\n","        for itw in range(0, it_w):\n","            w_start = itw*inner_shape[1]\n","            tp_img = image_pd[h_start:h_start+out_shape[0], w_start:w_start+out_shape[1], :]\n","\n","            # image pre-process\n","            tp_img = img_pre_process(tp_img.copy(), **kwargs)\n","            # print('tp_img', tp_img.shape)\n","\n","            tp_out = pred_fun(tp_img[np.newaxis, :])\n","            tp_out = np.squeeze(tp_out, axis=0)\n","\n","            # image post-process\n","            # tp_out = post-process\n","\n","            out_img[h_start:h_start+inner_shape[0], w_start:w_start+inner_shape[1], :] = tp_out[pd_up_h:pd_up_h+inner_shape[0], pd_lf_w:pd_lf_w+inner_shape[1], :]\n","\n","            # write video ##########################\n","            if make_video:\n","                tp = cv2.resize(out_img[:, :, 0], (wd, ht), interpolation=cv2.INTER_LINEAR)\n","                # print(np.unique(tp))\n","                # xixi = np.uint8((tp > 0.5)*255)\n","                xixi = tp > 1e-5\n","                mimi = np.uint8(tp[xixi] * 255)\n","                haha[xixi, 0] = mimi\n","                haha[xixi, 1] = mimi\n","                haha[xixi, 2] = mimi\n","                video_writer.write(haha)\n","\n","            print('haha!', h_start, w_start, count)\n","            count += 1\n","    if make_video:\n","        video_writer.release()\n","    return out_img[0:ori_shape[0], 0:ori_shape[1], :]\n","\n","\n","def predict_big_map_show(img_path, pred_fun=None, **kwargs):\n","    '''\n","    展示中间层图片\n","    注：由于没有类似predict_big_map切分图片的操作，这里对图片的大小严苛，需要形同训练图片大小才行，否则会报错，后续可增添相应的图片缩放等操作进行通用化处理。\n","    :param img_path: 图片路径\n","    :param pred_fun:前向计算模型，调用sess.run计算hed中间层，返回图片数据，可直接处理该数据进行可视化展示\n","    :param kwargs: 均值信息\n","    :return:无返回，调用该函数opencv弹窗显示中间图片\n","    '''\n","    image = cv2.imread(img_path, )\n","    # 如果图片只有二维，添加一维生成满足网络要求的占位符比如（?,224,224,1）\n","    if len(image.shape) == 2:\n","        image = np.expand_dims(image, axis=-1)\n","        gc.collect()\n","    image = image.astype(np.float32)  # cv2.imread后类型为unit8，转类型处理\n","    # 图片前置处理\n","    tp_img = img_pre_process(image.copy(), **kwargs)\n","    # 图片预测，这里相当于pred_fun为一个函数传入，这里调用该函数，该函数已经使用session对传入的图片进行处理，输出结果直接为hed网络中6张图片的数据\n","    tp_out = pred_fun(tp_img[np.newaxis, :])\n","    print(\"***********\")\n","    print(\"***********\")\n","    # numpy.squeeze把维度为1的条目去除，\n","    img1 = np.squeeze((tp_out[0] * 255).astype(np.uint8))\n","    img2 = np.squeeze((tp_out[1] * 255).astype(np.uint8))\n","    img3 = np.squeeze((tp_out[2] * 255).astype(np.uint8))\n","    img4 = np.squeeze((tp_out[3] * 255).astype(np.uint8))\n","    img5 = np.squeeze((tp_out[4] * 255).astype(np.uint8))\n","    img6 = np.squeeze((tp_out[5] * 255).astype(np.uint8))\n","    # 图集\n","    output_img = np.hstack([img1, img2, img3, img4, img5, img6])\n","    # 展示多个\n","    cv2.namedWindow('ouput_image', cv2.WINDOW_AUTOSIZE)\n","    cv2.imshow('ouput_image', output_img)\n","    cv2.waitKey(0)\n","    print(\"***********\")\n","    print(\"***********\")\n","\n","\n","if __name__ == '__main__':\n","    # 定义gpu和图片路径\n","    args = arg_parser()\n","    # 定义session的config配置\n","    config = sess_config(args)\n","    # 读取配置文件\n","    with open('cfg.yml') as file:\n","        cfg = yaml.load(file)\n","    # path = args.img_path\n","    # path = \"data/dataset/train_data/IMG_1580.JPG\"\n","    path = \"data/dataset/IMG_2717_224.JPG\"\n","\n","    # 读取高、宽、通道，均值等\n","    height = cfg['height']\n","    width = cfg['width']\n","    channel = cfg['channel']\n","    mean = cfg['mean']\n","\n","    # 定义session，HED网络\n","    sess = tf.Session(config=config)\n","    hed_class = HED(height=height, width=width, channel=channel)\n","    hed_class.vgg_hed()\n","    saver = tf.train.Saver()\n","    # 读取权重\n","    saver.restore(sess, 'data/weights/model_weights/vgg16_hed-120')\n","\n","    '''\n","    # 如果这样调用中间图片可视化展示将导致图片非常尖锐不平滑\n","    sides = [hed_class.side1,hed_class.side2,hed_class.side3,hed_class.side4,hed_class.side5,hed_class.fused_side]\n","    predict_big_map_show(img_path=path, out_shape=(224, 224), inner_shape=(224, 224), out_channel=1,pred_fun=(lambda ipt: sess.run(sides, feed_dict={hed_class.x: ipt})), mean=cfg['mean'])\n","    '''\n","    # sigmoid处理后图片更加平滑\n","    sides = [tf.sigmoid(hed_class.side1),\n","             tf.sigmoid(hed_class.side2),\n","             tf.sigmoid(hed_class.side3),\n","             tf.sigmoid(hed_class.side4),\n","             tf.sigmoid(hed_class.side5),\n","             tf.sigmoid(hed_class.fused_side)]\n","    # 可视化展示\n","    predict_big_map_show(img_path=path,pred_fun=(lambda ipt: sess.run(sides, feed_dict={hed_class.x: ipt})), mean=cfg['mean'])\n","\n","    # tf.add_n表示相加，这里的sides为相加后取均值实现图片融合\n","    sides = 1.0*tf.add_n(sides) / len(sides)\n","    # 图片预测\n","    output_img = predict_big_map(img_path=path, out_shape=(height, width), inner_shape=(height, width), out_channel=1,\n","                                 pred_fun=(lambda ipt: sess.run(sides, feed_dict={hed_class.x: ipt})), mean=cfg['mean'])\n","\n","    # 去除维度为1的，实现图片转化\n","    output_img = np.squeeze((output_img*255).astype(np.uint8))\n","    cv2.imwrite('./data/tb_gray_img.png', output_img)\n","    cv2.imwrite('./data/tb_black_img.png', 255*(output_img > 127))\n","    sess.close()\n","\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"NhBp871rDj8e"},"source":["# -*- coding: UTF-8 -*-\n","import numpy as np\n","import tensorflow as tf\n","import yaml\n","\n","'''\n","HED网络类\n","基于VGG16，所以模型形同VGG16，唯一注意点是concat处，加上concat导致梯度计算不出，不知是某个类库的问题还是其他未知问题\n","'''\n","\n","# HED网络定义类\n","class HED(object):\n","    def __init__(self, height, width, channel):\n","        # 定义图片长宽\n","        self.height = height\n","        self.width = width\n","        # 定义占位符\n","        self.x = tf.placeholder(tf.float32, (None, height, width, channel))\n","        # 定义配置属性，来自配置文件\n","        with open('cfg.yml') as file:\n","            self.cfg = yaml.load(file)\n","\n","    def vgg_hed(self):\n","        '''\n","        VGG16模型为2层卷积+reLU,池化，2层卷积+reLU，池化，3层卷积+reLU，池化，3层卷积+reLU，池化，3层卷积+reLU，池化，3层全连接+reLU,softmax输出\n","        :return: 中间5层图片及最后融合的图片共6个数据\n","        '''\n","        # block对应的函数是iteration层卷积+reLU\n","        bn1, relu1 = self.block(input_tensor=self.x, filters=64, iteration=2, dilation_rate=[(4, 4), (1, 1)], name='block1')\n","        mp1 = tf.layers.max_pooling2d(inputs=relu1, pool_size=(2, 2), strides=(2, 2), padding='same', name='max_pool1')\n","\n","        bn2, relu2 = self.block(input_tensor=mp1, filters=128, iteration=2, name='block2')\n","        mp2 = tf.layers.max_pooling2d(inputs=relu2, pool_size=(2, 2), strides=(2, 2), padding='same', name='max_pool2')\n","\n","        bn3, relu3 = self.block(input_tensor=mp2, filters=256, iteration=3, name='block3')\n","        mp3 = tf.layers.max_pooling2d(inputs=relu3, pool_size=(2, 2), strides=(2, 2), padding='same', name='max_pool3')\n","\n","        bn4, relu4 = self.block(input_tensor=mp3, filters=512, iteration=3, name='block4')\n","        mp4 = tf.layers.max_pooling2d(inputs=relu4, pool_size=(2, 2), strides=(2, 2), padding='same', name='max_pool4')\n","\n","        bn5, relu5 = self.block(input_tensor=mp4, filters=512, iteration=3, name='block5')\n","\n","        # self.side()对图片进行反卷积\n","        self.side1 = self.side(input_tensor=bn1, stride=(1, 1), name='side1', deconv=False)\n","        self.side2 = self.side(input_tensor=bn2, stride=(2, 2), name='side2')\n","        self.side3 = self.side(input_tensor=bn3, stride=(4, 4), name='side3')\n","        self.side4 = self.side(input_tensor=bn4, stride=(8, 8), name='side4')\n","        self.side5 = self.side(input_tensor=bn5, stride=(16, 16), name='side5')\n","        # sides原本对应side12345的合成，但是优化器迭代concat报错所以先直接采用第五层作为sides\n","        sides = self.side5\n","        '''\n","        t1 = [[1, 2, 3], [4, 5, 6]]  \n","        t2 = [[7, 8, 9], [10, 11, 12]]  \n","        tf.concat([t1, t2], 0)  # [[1, 2, 3], [4, 5, 6], [7, 8, 9], [10, 11, 12]]  \n","        tf.concat([t1, t2], 1)  # [[1, 2, 3, 7, 8, 9], [4, 5, 6, 10, 11, 12]]\n","        '''\n","        # sides = tf.concat(values=[self.side1, self.side2, self.side3, self.side4, self.side5], axis=3)\n","        # tf.layers.conv2d参数含义：filters输出通道数，kernel_size卷积核大小，strides卷积步长\n","        # 通过1×1卷积核实现通道数的缩放，sides通过concat后(?,224,224,5)通过卷积核变为(?,224,224,1)\n","        self.fused_side = tf.layers.conv2d(inputs=sides, filters=1, kernel_size=(1, 1), strides=(1, 1),\n","                                           use_bias=False, kernel_initializer=tf.constant_initializer(0.2), name='fused_side')\n","        return self.side1, self.side2, self.side3, self.side4, self.side5, self.fused_side\n","\n","    def block(self, input_tensor, filters, iteration, dilation_rate=None, name=None):\n","        '''\n","        相当于将HED网络分层分块，VGG16模型为2层(卷积+reLU),池化，2层(卷积+reLU)，池化，3层(卷积+reLU)，池化，3层(卷积+reLU)，池化，3层(卷积+reLU)，池化，3层全连接+reLU,softmax输出\n","        这里一个block对应iteration层的卷积+reLU\n","        :param input_tensor:输入的tensor\n","        :param filters:输出通道个数，等价于output_channels\n","        :param iteration:迭代次数，比如第一个block对应2层的(卷积+reLU)，这里iteration为2\n","        :param dilation_rate:扩张卷积\n","        :param name:命名空间，不重要，只在tensorboard可视化时看起来会简美些\n","        :return:经过(卷积+reLU)处理的tensor\n","        '''\n","        # dilation_rate表示扩张卷积，针对的是卷积核的大小，\n","        # 扩张卷积优点：扩展卷积在保持参数个数不变的情况下增大了卷积核的感受野，同时它可以保证输出的特征映射（feature map）的大小保持不变。\n","        # dilation_rate默认为（1，1）\n","        # 扩张卷积应用于图像语义分割问题中下采样会降低图像分辨率、丢失信息的一种卷积思路，所以实际上整个代码只是在VGG16第一层卷积中加入了扩张卷积\n","        if dilation_rate is None:\n","            dilation_rate = [(1, 1)]\n","        if len(dilation_rate) == 1:\n","            dilation_rate *= iteration\n","\n","        regularizer = tf.contrib.layers.l2_regularizer(self.cfg['weight_decay_ratio'])\n","        with tf.variable_scope(name):\n","            relu = input_tensor\n","            for it in range(iteration):\n","                tp_dilation_rate = dilation_rate.pop(0)\n","                print(\"hed_net:\",tp_dilation_rate)\n","                conv = tf.layers.conv2d(inputs=relu, filters=filters,\n","                                        kernel_size=(3, 3), strides=(1, 1), padding='same',\n","                                        activation=None, use_bias=True,\n","                                        kernel_regularizer=regularizer,\n","                                        dilation_rate=tp_dilation_rate,\n","                                        # kernel_initializer=tf.truncated_normal_initializer(stddev=0.5),\n","                                        name='conv{:d}'.format(it))\n","                # bn = tf.layers.batch_normalization(inputs=conv, axis=-1, name='bn{:d}'.format(it))\n","                bn = conv\n","                relu = tf.nn.relu(bn, name='relu{:d}'.format(it))\n","        return relu, relu\n","\n","    def side(self, input_tensor, stride, name, deconv=True):\n","        '''\n","        对图片进行反卷积\n","        :param input_tensor:输入的tensor\n","        :param stride:卷积步长，反卷积为扩大倍数\n","        :param name:命名空间名字\n","        :param deconv:是否反卷积\n","        :return:反卷积后的张量\n","        '''\n","        with tf.variable_scope(name):\n","            side = tf.layers.conv2d(inputs=input_tensor, filters=1, kernel_size=(1, 1), strides=(1, 1),\n","                                    padding='same',\n","                                    activation=None,\n","                                    bias_initializer=tf.constant_initializer(value=0),\n","                                    kernel_initializer=tf.constant_initializer(value=0),\n","                                    kernel_regularizer=tf.contrib.layers.l2_regularizer(0.0002))\n","            if deconv:\n","                # conv2d_transpose名字虽然叫转置，但实际上就是代表反卷积\n","                # stride步长，即扩大倍数\n","                side = tf.layers.conv2d_transpose(inputs=side, filters=1, kernel_size=(2*stride[0], 2*stride[1]),\n","                                                  strides=stride, padding='same',\n","                                                  kernel_initializer=tf.truncated_normal_initializer(stddev=0.1),\n","                                                  bias_initializer=tf.truncated_normal_initializer(stddev=0.1),\n","                                                  kernel_regularizer=tf.contrib.layers.l2_regularizer(self.cfg['weight_decay_ratio']),\n","                                                  activation=None)\n","            # 以上已经处理反卷积完成，这里在对反卷积完成后的张量做一次双线性插值图片处理\n","            side = tf.image.resize_images(images=side, size=(self.height, self.width),\n","                                          method=tf.image.ResizeMethod.BILINEAR)\n","        return side\n","\n","    def evaluate(self):\n","        '''\n","        评价，暂无，之后可用F1等评价\n","        :return:\n","        '''\n","        # evaluation criteria\n","        # accuracy\n","\n","        # precision\n","\n","        # recall\n","\n","        # F1 score\n","        pass\n","\n","    def summary(self):\n","        '''\n","        记录\n","        :return:\n","        '''\n","        max_outputs = 1\n","        tf.summary.image(name='orig_image_sm', tensor=self.x, max_outputs=max_outputs)\n","        tf.summary.image(name='side1_im', tensor=tf.sigmoid(self.side1), max_outputs=max_outputs, )\n","        tf.summary.image(name='side2_im', tensor=tf.sigmoid(self.side2), max_outputs=max_outputs, )\n","        tf.summary.image(name='side3_im', tensor=tf.sigmoid(self.side3), max_outputs=max_outputs, )\n","        tf.summary.image(name='side4_im', tensor=tf.sigmoid(self.side4), max_outputs=max_outputs, )\n","        tf.summary.image(name='side5_im', tensor=tf.sigmoid(self.side5), max_outputs=max_outputs, )\n","        tf.summary.image(name='fused_side_im', tensor=tf.sigmoid(self.fused_side), max_outputs=max_outputs, )\n","\n","        tf.summary.histogram(name='side1_hist', values=tf.sigmoid(self.side1))\n","        tf.summary.histogram(name='side2_hist', values=tf.sigmoid(self.side2))\n","        tf.summary.histogram(name='side3_hist', values=tf.sigmoid(self.side3))\n","        tf.summary.histogram(name='side4_hist', values=tf.sigmoid(self.side4))\n","        tf.summary.histogram(name='side5_hist', values=tf.sigmoid(self.side5))\n","        tf.summary.histogram(name='fused_side_hist', values=tf.sigmoid(self.fused_side))\n","\n","    def assign_init_weights(self, sess=None):\n","        '''\n","        初始化权重,读取VGG16权重文件进行权重初始化\n","        :param sess: session\n","        :return:\n","        '''\n","        with open(self.cfg['init_weights'], 'rb') as file:\n","            weights = np.load(file, encoding='latin1').item()\n","        with tf.variable_scope('block1', reuse=True):\n","            k = tf.get_variable(name='conv0/kernel')\n","            sess.run(tf.assign(k, weights['conv1_1'][0]))\n","            k = tf.get_variable(name='conv0/bias')\n","            sess.run(tf.assign(k, weights['conv1_1'][1]))\n","\n","            k = tf.get_variable(name='conv1/kernel')\n","            sess.run(tf.assign(k, weights['conv1_2'][0]))\n","            k = tf.get_variable(name='conv1/bias')\n","            sess.run(tf.assign(k, weights['conv1_2'][1]))\n","        print('assign first block done !')\n","        with tf.variable_scope('block2', reuse=True):\n","            k = tf.get_variable(name='conv0/kernel')\n","            sess.run(tf.assign(k, weights['conv2_1'][0]))\n","            k = tf.get_variable(name='conv0/bias')\n","            sess.run(tf.assign(k, weights['conv2_1'][1]))\n","\n","            k = tf.get_variable(name='conv1/kernel')\n","            sess.run(tf.assign(k, weights['conv2_2'][0]))\n","            k = tf.get_variable(name='conv1/bias')\n","            sess.run(tf.assign(k, weights['conv2_2'][1]))\n","        print('assign second block done !')\n","        with tf.variable_scope('block3', reuse=True):\n","            k = tf.get_variable(name='conv0/kernel')\n","            sess.run(tf.assign(k, weights['conv3_1'][0]))\n","            k = tf.get_variable(name='conv0/bias')\n","            sess.run(tf.assign(k, weights['conv3_1'][1]))\n","\n","            k = tf.get_variable(name='conv1/kernel')\n","            sess.run(tf.assign(k, weights['conv3_2'][0]))\n","            k = tf.get_variable(name='conv1/bias')\n","            sess.run(tf.assign(k, weights['conv3_2'][1]))\n","\n","            k = tf.get_variable(name='conv2/kernel')\n","            sess.run(tf.assign(k, weights['conv3_3'][0]))\n","            k = tf.get_variable(name='conv2/bias')\n","            sess.run(tf.assign(k, weights['conv3_3'][1]))\n","        print('assign third block done !')\n","        with tf.variable_scope('block4', reuse=True):\n","            k = tf.get_variable(name='conv0/kernel')\n","            sess.run(tf.assign(k, weights['conv4_1'][0]))\n","            k = tf.get_variable(name='conv0/bias')\n","            sess.run(tf.assign(k, weights['conv4_1'][1]))\n","\n","            k = tf.get_variable(name='conv1/kernel')\n","            sess.run(tf.assign(k, weights['conv4_2'][0]))\n","            k = tf.get_variable(name='conv1/bias')\n","            sess.run(tf.assign(k, weights['conv4_2'][1]))\n","\n","            k = tf.get_variable(name='conv2/kernel')\n","            sess.run(tf.assign(k, weights['conv4_3'][0]))\n","            k = tf.get_variable(name='conv2/bias')\n","            sess.run(tf.assign(k, weights['conv4_3'][1]))\n","        print('assign fourth block done !')\n","        with tf.variable_scope('block5', reuse=True):\n","            k = tf.get_variable(name='conv0/kernel')\n","            sess.run(tf.assign(k, weights['conv5_1'][0]))\n","            k = tf.get_variable(name='conv0/bias')\n","            sess.run(tf.assign(k, weights['conv5_1'][1]))\n","\n","            k = tf.get_variable(name='conv1/kernel')\n","            sess.run(tf.assign(k, weights['conv5_2'][0]))\n","            k = tf.get_variable(name='conv1/bias')\n","            sess.run(tf.assign(k, weights['conv5_2'][1]))\n","\n","            k = tf.get_variable(name='conv2/kernel')\n","            sess.run(tf.assign(k, weights['conv5_3'][0]))\n","            k = tf.get_variable(name='conv2/bias')\n","            sess.run(tf.assign(k, weights['conv5_3'][1]))\n","        weights = None  # gc\n","        print('assign fifth block done !')\n","        print('net initializing successfully with vgg16 weights trained by imagenet data')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"BwezDsaoDZ-c"},"source":["# -*- coding: UTF-8 -*-\n","from __future__ import print_function\n","import tensorflow as tf\n","import yaml\n","\n","'''\n","损失函数类\n","1.对应两种损失函数计算方法，calc_loss和focal_loss\n","2.主要研究了calc_loss,该损失函数涉及两个超参数，is_deep_supervised是否深层监督即是否考虑VGG16中间层的输出图，use_weight_regularizer是否正则化\n","'''\n","\n","# 损失函数\n","class HedLoss(object):\n","    def __init__(self, sides):\n","        self.sides = sides  # sides对应hed网络输出的6个图\n","        self.loss = 0.0     # loss对应calc_loss计算的损失函数\n","        self.floss = 0.0    # floss对应focal_loss计算的损失函数\n","        with open('cfg.yml') as file:\n","            self.cfg = yaml.load(file)\n","        self.label = tf.placeholder(tf.float32, (None, self.cfg['height'], self.cfg['width'], 1))   # 定义标签图占位符\n","        # self.calc_loss()\n","\n","    def calc_loss(self):\n","        '''\n","        损失函数\n","        :return: 损失函数计算值\n","        '''\n","        # is_deep_supervised是否深层监督，若深层监督则考虑HED网络过程中每一张图的权重并取均值\n","        # 如果不考虑深层监督，则直接考虑融合后图的损失\n","        # 个人初步想法：考虑深层监督，则每一次迭代实现分层次的计算损失修改每一层次的权重，再计算融合图，修改权重，实现权重更新粒度更加精确，但是最终效果其实只与融合图有关，所以最后结果尚待测试\n","        if self.cfg['is_deep_supervised']:\n","            for n in range(len(self.sides)-1):\n","                tp_loss = self.cfg['sides_weights'][n] * tf.nn.weighted_cross_entropy_with_logits(targets=self.label, logits=self.sides[n], pos_weight=self.cfg['pos_weights'])\n","                self.loss += tf.reduce_mean(tp_loss)\n","        self.loss += tf.reduce_mean(tf.nn.weighted_cross_entropy_with_logits(targets=self.label, logits=self.sides[-1], pos_weight=self.cfg['pos_weights']))\n","\n","        # tf.get_collection零存整取获取数据，tf.GraphKeys.REGULARIZATION_LOSSES形同名字，正则化处理\n","        reg_loss = tf.get_collection(tf.GraphKeys.REGULARIZATION_LOSSES)\n","        if self.cfg['use_weight_regularizer']:\n","            self.loss = tf.add_n(reg_loss) + self.loss\n","\n","        return self.loss\n","\n","\n","    def focal_loss(self):\n","        '''\n","        另一种损失函数\n","        :return: 损失函数计算值\n","        '''\n","        if self.cfg['is_deep_supervised']:\n","            for n in range(len(self.sides) - 1):\n","                sg_p = tf.nn.sigmoid(self.sides[n])\n","                sg_n = 1.0 - sg_p\n","                sg_p += 1e-5\n","                sg_n += 1e-5\n","                pos_num = tf.reduce_sum(tf.cast(self.label > 0.99, tf.float32))\n","                neg_num = tf.reduce_sum(tf.cast(self.label < 0.01, tf.float32))\n","\n","                pos = -self.label*sg_n*sg_n*tf.log(sg_p)\n","                pos = tf.reduce_sum(pos) / (pos_num+1e-5)\n","\n","                neg = -(1.0-self.label)*sg_p*sg_p*tf.log(sg_n)\n","                neg = tf.reduce_sum(neg) / (neg_num+1e-5)\n","                self.floss = self.floss + 0.25*pos + neg*0.75\n","\n","        sg_p = tf.nn.sigmoid(self.sides[-1])\n","        sg_n = 1.0 - sg_p\n","        sg_p += 1e-5\n","        sg_n += 1e-5\n","        pos_num = tf.reduce_sum(tf.cast(self.label > 0.99, tf.float32))\n","        neg_num = tf.reduce_sum(tf.cast(self.label < 0.01, tf.float32))\n","\n","        pos = -self.label * sg_n * sg_n * tf.log(sg_p)\n","        pos = tf.reduce_sum(pos) / (pos_num+1e-5)\n","\n","        neg = -(1.0 - self.label) * sg_p * sg_p * tf.log(sg_n)\n","        neg = tf.reduce_sum(neg) / (neg_num+1e-5)\n","        self.floss = self.floss + 0.25*pos + neg*0.75\n","        if self.cfg['use_weight_regularizer']:\n","            reg_loss = tf.get_collection(tf.GraphKeys.REGULARIZATION_LOSSES)\n","            self.floss += tf.add_n(reg_loss)\n","        return self.floss\n","\n","\n","    def summary(self):\n","        '''\n","        统计\n","        :return:\n","        '''\n","        tf.summary.scalar(name='loss_sm', tensor=self.loss)\n","        tf.summary.scalar(name='floss_sm', tensor=self.floss)\n","        max_outputs = 1\n","        tf.summary.image(name='label_sm', tensor=self.label, max_outputs=max_outputs, )"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":186},"id":"F5VmpieVCp-q","executionInfo":{"status":"error","timestamp":1636031106760,"user_tz":-480,"elapsed":878,"user":{"displayName":"孟维民","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01682933707738661337"}},"outputId":"bd59a970-79d0-4b93-89e4-b27ffd87e4bf"},"source":["# -*- coding: UTF-8 -*-\n","import numpy as np\n","import tensorflow as tf\n","import yaml\n","from hed_net import HED\n","from loss import HedLoss\n","import os\n","import cv2\n","import argparse\n","import random\n","from time import time\n","import matplotlib.pyplot as plt\n","\n","'''\n","训练HED网络主函数\n","1.超参数通过cfg.yml配置更改\n","2.采用batch的模式训练，每一轮迭代遍历所有训练集(处理时会打乱顺序）,本机对于224×224图片来说，batch_size=2能够不卡顿的运行，可以适当增加batch_size提高迭代速度\n","3.暂未写损失函数可视化！\n","'''\n","\n","# dataSet存放数据文件，包括图片信息和标签信息\n","class DataSet(object):\n","    def __init__(self):\n","        # 读取配置文件\n","        with open('cfg.yml') as file:\n","            self.cfg = yaml.load(file)\n","        self.imgs = None    # 图片信息\n","        self.labels = None  # 标签信息\n","        self.samples_num = 0    # 样本数量\n","        self.read_data()    # 调用函数加载图片和标签\n","\n","    def read_data(self):\n","        '''\n","        读取训练图片文件和标签图片文件\n","        :return:\n","        '''\n","        img_names = []\n","        label_names = []\n","        # 配置文件cfg.yml中file_name对应train.txt，记录一一对应的训练图片与标签图片，存放在img_names,label_names,为之后读取做准备\n","        with open(self.cfg['file_name']) as file:\n","            while True:\n","                il = file.readline(1500)    # 如果样本数据大于1500，修改该值\n","                if not il:\n","                    break\n","                a = il.split(sep=' ')\n","                img_names.append(a[0])\n","                label_names.append(a[1][0:-1])  # remove '\\n'\n","        self.samples_num = len(img_names)\n","        print('total image num: ', self.samples_num)\n","        # 初始化self.imgs和self.labels，开辟对应大小空间和类型，与配置文件设置有关\n","        self.imgs = np.zeros((len(img_names), self.cfg['height'], self.cfg['width'], self.cfg['channel']), np.float32)\n","        self.labels = np.zeros((len(img_names), self.cfg['height'], self.cfg['width'], 1), np.float32)\n","        # cv2.imread读取后格式为unit8，所以遍历所有图片及标签进行读取图片并设置格式\n","        # 注：这里对标签进行了归一化处理，但并未对训练图片进行归一化处理，后续可考虑训练时对训练图片进行归一化看训练效果，同时要注意修改测试时同样处理方式\n","        for it in range(len(self.labels)):\n","            tp_img = cv2.imread(os.path.join(self.cfg['image_path'], img_names[it]))\n","            tp_label = cv2.imread(os.path.join(self.cfg['image_path'], label_names[it]), cv2.IMREAD_GRAYSCALE)  # cv2.IMREAD_GRAYSCALE加载一张灰度图\n","            self.imgs[it, :, :, :] = tp_img.astype(np.float32)\n","            self.labels[it, :, :, 0] = (tp_label/255).astype(np.float32)\n","        # 图像减去均值是为了让损失函数平滑收敛，但是这里的均值是直接读取配置文件\n","        # 若之后搭建训练集后可考虑计算下均值做相应改变\n","        self.imgs -= self.cfg['mean']\n","        print('images and labels reading done!')\n","\n","    def batch_iterator(self, shuffle=False):\n","        '''\n","        根据batch进行迭代，利用shuffle进行打乱顺序，批次大小配置文件配置\n","        :param shuffle: 是否打乱\n","        :return: 单个训练图片和标签文件用于迭代\n","        '''\n","        batch_size = self.cfg['batch_size']\n","        num_examples = len(self.imgs)\n","        idx = list(range(num_examples))\n","        if shuffle:\n","            random.shuffle(idx)\n","        for i in range(0, num_examples, batch_size):\n","            imgs = self.imgs[idx[i:min(i+batch_size, num_examples)], :, :, :]\n","            labels = self.labels[idx[i:min(i+batch_size, num_examples)], :, :, :]\n","            # print('batch_size: ', labels.shape[0])\n","            # yield是一个生成器generator，简单的说就是每次执行到yield就返回，下次又迭代进入时又从yield处继续，实现迭代\n","            yield imgs, labels\n","\n","\n","def arg_parser():\n","    '''\n","    GPU配置parser\n","    :return:\n","    '''\n","    parser = argparse.ArgumentParser()\n","    parser.add_argument('-gpu', type=str, required=False, default='0')\n","    args = parser.parse_args()\n","    return args\n","\n","\n","def sess_config(args=None):\n","    '''\n","    session的config配置，若没有GPU将直接使用CPU，不会报错\n","    :param args:\n","    :return: 配置config\n","    '''\n","    log_device_placement = True  # 是否打印设备分配日志\n","    allow_soft_placement = True  # 如果你指定的设备不存在，允许TF自动分配设备\n","    gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=0.95, allow_growth=True)\n","    os.environ['CUDA_VISIBLE_DEVICES'] = args.gpu  # 使用 GPU 0\n","    config1 = tf.ConfigProto(log_device_placement=log_device_placement,\n","                            allow_soft_placement=allow_soft_placement,\n","                            gpu_options=gpu_options)\n","    return config1\n","\n","\n","if __name__ == \"__main__\":\n","    # 读取配置文件\n","    with open('cfg.yml') as file:\n","        cfg = yaml.load(file)\n","    args = arg_parser()     # 配置\n","    config = sess_config(args)   # session的config配置\n","\n","    # 训练数据\n","    dataset = DataSet()\n","    # HED网络定义\n","    hed_class = HED(height=cfg['height'], width=cfg['width'], channel=cfg['channel'])\n","    sides = hed_class.vgg_hed()\n","    # 损失函数定义\n","    loss_class = HedLoss(sides)\n","    loss = loss_class.calc_loss()\n","    # 优化器，采用动态学习率\n","    global_step = tf.Variable(0, trainable=False)\n","    learning_rate = tf.train.exponential_decay(learning_rate=1e-5,\n","                                               global_step=global_step,\n","                                               decay_steps=10000,\n","                                               decay_rate=0.1,\n","                                               staircase=True)\n","    train_op = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(loss, global_step=global_step)\n","    # summary记录，用于tensorboard可视化\n","    tf.summary.scalar(name='lr', tensor=learning_rate)\n","    hed_class.summary()\n","    loss_class.summary()\n","    merged_summary_op = tf.summary.merge_all()\n","\n","    startTime = time()\n","    # 训练\n","    with tf.Session(graph=tf.get_default_graph(), config=config) as sess:\n","        saver = tf.train.Saver()\n","\n","        # session变量初始化\n","        sess.run(tf.global_variables_initializer())\n","        # 初始化HED网络权重（HED网络基于VGG16，直接使用VGG16权重初始化）\n","        hed_class.assign_init_weights(sess)\n","\n","        # 断点续训\n","        ckpt_dir = cfg['model_weights_path']\n","        ckpt = tf.train.latest_checkpoint(ckpt_dir)\n","        if ckpt != None:\n","            saver.restore(sess, ckpt)\n","            # sess.run(tf.assign(global_step, 0))\n","            print('saver restore finish')\n","        else:\n","            print(\"training from scratch\")\n","\n","\n","\n","        # 日志记录\n","        summary_writer = tf.summary.FileWriter(cfg['log_dir'], graph=sess.graph, flush_secs=15)\n","\n","        step = 0    # 记录summary的step\n","        # 通过配置文件max_epochs最大迭代次数进行训练\n","        for epoch in range(1, cfg['max_epochs']+1):\n","            for imgs, labels in dataset.batch_iterator():   # 通过迭代获取训练图片和标签信息\n","                '''\n","                # 输出中间过程图片\n","                print(\"*************\")\n","                print(\"*************\")\n","                sides_show = sess.run([sides],feed_dict={hed_class.x: imgs})\n","                picture_batch1 = sides_show[0][0] #对应第一层输出的图片batch\n","\n","                plt.subplot(331)\n","                outImage = sides_show[0][0]\n","                plt.imshow(outImage[0, :, :, 0])\n","                plt.subplot(332)\n","                outImage = sides_show[0][1]\n","                plt.imshow(outImage[0, :, :, 0])\n","                plt.subplot(333)\n","                outImage = sides_show[0][2]\n","                plt.imshow(outImage[0, :, :, 0])\n","                plt.subplot(334)\n","                outImage = sides_show[0][3]\n","                plt.imshow(outImage[0, :, :, 0])\n","                plt.subplot(335)\n","                outImage = sides_show[0][4]\n","                plt.imshow(outImage[0, :, :, 0])\n","                plt.subplot(336)\n","                outImage = sides_show[0][5]\n","                plt.imshow(outImage[0, :, :, 0])\n","                plt.show()\n","\n","                print(\"*************\")\n","                # print(sides_show)\n","                # print(\"*************\")\n","                # print(\"*************\")\n","                '''\n","                # 核心训练语句，利用训练图片和标签图片信息代入优化器进行训练，记录summary\n","                merged_summary, _ = sess.run([merged_summary_op, train_op],feed_dict={hed_class.x: imgs, loss_class.label: labels})\n","                if not (step % 1):\n","                    summary_writer.add_summary(merged_summary, global_step=step)\n","                    print('save a merged summary !')\n","                step += 1\n","                print('global_step:', sess.run(global_step), 'epoch: ', epoch)\n","\n","            # 配置文件设置多少代输出一次模型\n","            if not epoch % cfg['snapshot_epochs']:\n","                saver.save(sess=sess, save_path=os.path.join(cfg['model_weights_path'], 'vgg16_hed'), global_step=epoch)\n","                print('save a snapshoot !')\n","        summary_writer.close()\n","        saver.save(sess=sess, save_path=os.path.join(cfg['model_weights_path'], 'vgg16_hed'), global_step=epoch)\n","        print('save final model')\n","\n","    duration = time() - startTime\n","    print(\"train takes:\", \"{:.2f}\".format(duration))"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["usage: ipykernel_launcher.py [-h] [-gpu GPU]\n","ipykernel_launcher.py: error: unrecognized arguments: -f /root/.local/share/jupyter/runtime/kernel-08c5f861-0eaa-4e97-833d-5b4aadeaf19b.json\n"]},{"output_type":"error","ename":"SystemExit","evalue":"ignored","traceback":["An exception has occurred, use %tb to see the full traceback.\n","\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 2\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py:2890: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n","  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"]}]}]}